<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Philosophy 101</title>
<meta name="author" content="(Colin McLear)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="file:///Users/Roambot/bin/reveal.js/css/reveal.css"/>

<link rel="stylesheet" href="file:///Users/Roambot/bin/reveal.js/css/theme/solarized.css" id="theme"/>

<link rel="stylesheet" href="/Users/Roambot/projects/phil101/content/slides/local.css"/>
<link rel="stylesheet" href="file:///Users/Roambot/bin/reveal.js/lib/css/zenburn.css"/>
<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'file:///Users/Roambot/bin/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<meta name="description" content="PHIL 101 Slides">
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1>Philosophy 101</h1><h3>Fall 2016</h3><h4>phil101.colinmclear.net</h4>
</section>
<section id="table-of-contents">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#/slide-orgheadline21">Can Machines Think?</a>
<ul>
<li><a href="#/slide-orgheadline1">Two Questions</a></li>
<li><a href="#/slide-orgheadline2">Strong &amp; Weak AI</a></li>
<li><a href="#/slide-orgheadline3">The Imitation Game</a></li>
<li><a href="#/slide-orgheadline4">The Turing Test</a></li>
<li><a href="#/slide-orgheadline5">Strong AI &amp; the Turing Test</a></li>
<li><a href="#/slide-orgheadline6">The Chinese Room Argument</a></li>
<li><a href="#/slide-orgheadline7">Syntax &amp; Semantics</a></li>
<li><a href="#/slide-orgheadline8">Syntax &amp; Semantics</a></li>
<li><a href="#/slide-orgheadline9">The  Argument Clarified</a></li>
<li><a href="#/slide-orgheadline10">What Does the Argument Intend to Prove?</a></li>
<li><a href="#/slide-orgheadline20">Objections to the Chinese Room Argument</a></li>
</ul>
</li>
</ul>
</div>
</div>
</section>
<section>
<section id="slide-orgheadline21">
<h2 id="orgheadline21">Can Machines Think?</h2>
<div class="outline-text-2" id="text-orgheadline21">
</div></section>
</section>
<section>
<section id="slide-orgheadline1">
<h3 id="orgheadline1">Two Questions</h3>
<aside class="notes">
<ul>
<li>Crane construes mental representation as fundamental but doesn't
explain what it is about mental representation that allows it to
represent</li>
<li>Question 2 is in Crane's terms: Could a machine exhibit states that are intrinsically representational?</li>

</ul>

</aside>

<ol>
<li class="fragment appear">Can a physical system capable of performing certain functions think?</li>
<li class="fragment appear">Can a sufficiently sophisticated computer program think?
<ul>
<li class="fragment appear">Is the mind related to the brain like software is to hardware?</li>

</ul></li>

</ol>

</section>
<section>
<p>
Could a sufficiently advanced computer qualify as a thinking being?
</p>

<blockquote nil>
<p>
A. Yes<br  />
B. No
</p>
</blockquote>

</section>
</section>
<section>
<section id="slide-orgheadline2">
<h3 id="orgheadline2">Strong &amp; Weak AI</h3>
<dl>
<dt class="fragment appear">Strong AI:</dt><dd class="fragment appear">thinking is constituted by the manipulation of formal
symbols, such as occurs in a computer program</dd>
<dt class="fragment appear">Weak AI:</dt><dd class="fragment appear">thinking may be modeled by formal symbol systems, such as
computer programs</dd>

</dl>

</section>
</section>
<section>
<section id="slide-orgheadline3">
<h3 id="orgheadline3">The Imitation Game</h3>
<ul>
<li class="fragment appear">Can you guess, using a series of questions, which of two conversation
partners is a machine and which a human?</li>
<li class="fragment appear">Questions may be of all kinds:
<ul>
<li class="fragment appear">what's your name</li>
<li class="fragment appear">what's your favorite color?</li>
<li class="fragment appear">what does the smell of freshly cut grass remind you of?</li>

</ul></li>

</ul>

</section>
</section>
<section>
<section id="slide-orgheadline4">
<h3 id="orgheadline4">The Turing Test</h3>
<blockquote nil>
<p>
I believe that in about fifty years' time it will be possible to
programme computers&#x2026;to make them play the imitation game so well
that an average interrogator will not have more than 70 percent chance
of making the right identification after five minutes of
questioning&#x2026;I believe that at the end of the century the use of
words and general educated opinion will have altered so much that one
will be able to speak of machines thinking without expecting to be
contradicted. (Alan Turing)
</p>
</blockquote>

</section>
<section>
<ol>
<li>For some arbitrary time period, there may be no discernible
difference between the linguistic behavior of a person and that of a
machine</li>
<li class="fragment appear">If there is no discernible difference in linguistic behavior between
man and machine, then there is no reason to think that there is any
underlying difference in the causes of that behavior</li>
<li class="fragment appear">\(\therefore\) If we are willing to say that it is intelligent thought
that is the cause of the linguistic behavior in the person we should
be willing to say the same thing about the machine</li>

</ol>

</section>
</section>
<section>
<section id="slide-orgheadline5">
<h3 id="orgheadline5">Strong AI &amp; the Turing Test</h3>
<ul>
<li>Any computer that can pass the Turing Test for arbitrarily long
periods of time will, according to strong AI, qualify as a thinking
machine</li>

</ul>

</section>
</section>
<section>
<section id="slide-orgheadline6">
<h3 id="orgheadline6">The Chinese Room Argument</h3>
<blockquote nil>
<p>
suppose I am placed in a room containlng baskets full of Chinese
symbols. Suppose also that I am given a rule book in English for
matching Chinese symbols with other Chinese symbols. The rules
identify the symbols entirely by their shapes and do not require that
I understand any of them. The rules might say such things as, "Take
a&#x2026;sign from basket number one and put it next to a&#x2026;sign from
basket number two." Imagine that people outside the room who
understand Chinese hand in small bunches of symbols and that in
response I manipulate the symbols according to the rule book and hand
back more small bunches of symbols.
</p>
</blockquote>

</section>
<section>

<blockquote nil>
<p>
Now, the rule book is the "computer program." The people who wrote it
are "programmers," and I am the "computer." The baskets full of
symbols are the "data base," the small bunches that are handed in to
me are "questions" and the bunches I then hand out are "answers."
</p>
</blockquote>

</section>
<section>


<div class="figure">
<p><img src="file:///Users/Roambot/Dropbox/Work/Teaching/Phil101/MarkdownSlides/rulebook.jpg" alt="rulebook.jpg" style="margin:auto; display:block; text-align:center; min-width: 90%; height: auto;" />
</p>
</div>
<p style="text-align:center">
The rulebook 
</p>

</section>
<section>


<div class="figure">
<p><img src="file:///Users/Roambot/Dropbox/Work/Teaching/Phil101/MarkdownSlides/CRoom.jpg" alt="CRoom.jpg" style="margin:auto; display:block; text-align:center; min-width: 100%; height: auto" />
</p>
</div>
<p style="text-align:center">
The Chinese room
</p>

</section>
<section>

<blockquote nil>
<p>
Now suppose that the rule book is written in such a way that my
"answers" to the "questions" are indistinguishable from those of a
native Chinese speaker. For example, the people outside might hand me
some symbols that unknown to me mean, "What's your favorite color?"
and I might after going through the rules give back symbols that, also
unknown to me, mean, "My favorite is blue, but I also like green a
lot." I satisfy the Turing test for understanding Chinese. All the
same, I am totally ignorant of Chinese. And there is no way I could
come to understand Chinese in the system as described, since there is
no way that I can learn the meanings of any of the symbols. Like a
computer, I manipulate symbols, but I attach no meaning to the
symbols. (Searle, 26)
</p>
</blockquote>

</section>
<section>


<div class="figure">
<p><img src="file:///Users/Roambot/Dropbox/Work/Teaching/Phil101/MarkdownSlides/CRoom2.jpg" alt="CRoom2.jpg" style="margin:auto; display:block; text-align:center; min-width: 100%; height: auto" />
</p>
</div>
<p style="text-align:center">
The Chinese room 
</p>

</section>
</section>
<section>
<section id="slide-orgheadline7">
<h3 id="orgheadline7">Syntax &amp; Semantics</h3>
<dl>
<dt class="fragment appear">Syntax:</dt><dd class="fragment appear">the formal or structural features of a symbol system which
determine which expressions are legitimate members of the system and
which are not</dd>

</dl>

<p>
<br  />
</p>
<ul>
<li class="fragment appear">The syntax of English (its grammar) requires that all complete
sentences have a noun phrase and a verb phrase
<ul>
<li class="fragment appear">'John goes to school' vs. 'school John to goes'</li>

</ul></li>

</ul>

</section>
</section>
<section>
<section id="slide-orgheadline8">
<h3 id="orgheadline8">Syntax &amp; Semantics</h3>
<dl>
<dt>Semantics:</dt><dd>The system of meanings assigned to a symbol system,
given by determining the referents of the symbols and the truth
conditions of symbol strings</dd>

</dl>

<p>
<br  />
</p>
<ul>
<li class="fragment appear">'Schnee' refers to snow</li>
<li class="fragment appear">'weiß' refers to the property of being white</li>
<li class="fragment appear">'Schnee ist weiß' is true just in case snow is white</li>

</ul>

</section>
</section>
<section>
<section id="slide-orgheadline9">
<h3 id="orgheadline9">The  Argument Clarified</h3>
<ol>
<li class="fragment appear">Programs are purely formal (syntactic)</li>
<li class="fragment appear">Human minds have mental contents (semantics)</li>
<li class="fragment appear">Syntax by itself is neither constitutive of, nor sufficient for,
semantic content</li>
<li class="fragment appear">\(\therefore\) Programs by themselves are not constitutive of nor
sufficient for minds</li>

</ol>

</section>
</section>
<section>
<section id="slide-orgheadline10">
<h3 id="orgheadline10">What Does the Argument Intend to Prove?</h3>
<ul>
<li class="fragment appear">You can't get semantic content from syntax alone</li>
<li class="fragment appear">A system must have more than purely syntactic properties in order to
possess intentional states</li>

</ul>
</section>
</section>
<section>
<section id="slide-orgheadline20">
<h3 id="orgheadline20">Objections to the Chinese Room Argument</h3>
<div class="outline-text-3" id="text-orgheadline20">
</div></section>
<section id="slide-orgheadline11">
<h4 id="orgheadline11">Two Objections</h4>
<ol>
<li class="fragment appear">The 'Systems' Objection</li>
<li class="fragment appear">The 'Implementation' Objection</li>

</ol>

</section>
<section id="slide-orgheadline12">
<h4 id="orgheadline12">The 'Systems' Objection</h4>
<ul>
<li class="fragment appear">Perhaps the person <i>in</i> the Chinese room does not understand Chinese
but the <i>Chinese Room itself</i> understands Chinese</li>
<li class="fragment appear">Since the Chinese room is the proper analogue to the computer
program, and not the person <i>in</i> the Chinese room, Searle's example
proves nothing</li>

</ul>

</section>
<section id="slide-orgheadline13">
<h4 id="orgheadline13">Searle's Reply</h4>
<blockquote nil>
<p>
My response to the systems theory is quite simple: let the individual
internalize all of these elements of the system. He memorizes the
rules in the ledger and the data banks of Chinese symbols, and he does
all the calculations in his head. The individual then incorporates the
entire system. There isn't anything at all to the system that he does
not encompass. We can even get rid of the room and suppose he works
outdoors. All the same, he understands nothing of the Chinese, and a
fortiori neither does the system, because there isn't anything in the
system that isn't in him. If he doesn't understand, then there is no
way that the system could understand because the system is just a part
of him.
</p>
</blockquote>

</section>
<section id="slide-orgheadline14">
<h4 id="orgheadline14">Pryor's Rebuttal (I) Searle's argument is invalid</h4>
<blockquote nil>
<p>
Searle: "[The man in the room] understands nothing of the Chinese, and
[therefore] neither does the system, because there isn't anything in
the system that isn't in him"
</p>
</blockquote>

<ul>
<li class="fragment appear">This is a bad inference&#x2014;compare:</li>

</ul>
<blockquote  class="fragment (appear)">
<p>
Searle doesn't weigh 3 pounds, and therefore neither does his heart,
because there is nothing in his heart that isn't in him
</p>
</blockquote>

</section>
<section>

<ul>
<li>the form of inference Searle uses here doesn't generalize to other
inferences with the same kind of form
<ul>
<li class="fragment appear">leaves open the possibility that the particular argument Searle
makes here is true</li>

</ul></li>

</ul>

</section>
<section id="slide-orgheadline15">
<h4 id="orgheadline15">Pryor's Rebuttal (II) Internalization is irrelevant</h4>
<blockquote nil>
<p>
Searle: "If he doesn't understand, then there is no way that the
system could understand because the system is just a part of him."
</p>
</blockquote>

<ul>
<li class="fragment appear">Consider a software emulator
<ul>
<li class="fragment appear">allows one operating system to run 'on top of' another using the
same hardware
<ul>
<li class="fragment appear">Mac computers can emulate the Windows OS</li>

</ul></li>

</ul></li>

</ul>

</section>
<section>

<ul>
<li><p>
Assume a Mac runnning its OS <i>plus</i> an emulation of Windows OS
</p>
<ol>
<li class="fragment appear">The Windows OS is integrated or incorporated into the Mac OS</li>
<li class="fragment appear">Nevertheless, the states of the 'incorporated' Windows OS are in
many ways independent of the Mac OS and its states</li>

</ol>
<ul>
<li class="fragment appear">Windows may crash and become unresponsive, while the Mac software
(including the emulator) keeps running</li>
<li class="fragment appear">Windows might be treating Internet Explorer as the frontmost,
active program; but&#x2013;if you don't have the emulator software
active in your Mac&#x2013;the Mac software could be treating Safari as
its frontmost, active program</li>

</ul></li>

</ul>

</section>
<section>
<blockquote nil>
<p>
when Jack memorizes all the instructions in the Chinese book, he
becomes like the Mac software, and the Chinese room software becomes
like the emulated Windows software. Jack fully incorporates the
Chinese room software. That does not mean that Jack shares all the
states of the Chinese room software, nor that it shares all of his
states. If the Chinese room software crashes, Jack may keep going
fine. If the Chinese room software is in a state of believing that
China was at its cultural peak during the Han dynasty, that does not
mean that Jack is also in that state. And so on. In particular, for
the Chinese room software to understand some Chinese symbol, it is not
required that Jack also understand that symbol.
</p>
</blockquote>

</section>
<section>

<ul>
<li>Problem 2: 'Internalizing' the Chinese room program is irrelevant
<ul>
<li class="fragment appear">two programs running on the same hardware need not share all of
the same (or any of the same) states</li>

</ul></li>

</ul>

</section>
<section id="slide-orgheadline16">
<h4 id="orgheadline16">Summary of Pryor's Rebuttals:</h4>
<ol>
<li class="fragment appear">Searle's argument is invalid
<ul>
<li class="fragment appear">the form of inference Searle uses here doesn't generalize to other
inferences with the same kind of form in a way that preserves
truth</li>

</ul></li>
<li class="fragment appear">'Internalization' is irrelevant
<ul>
<li class="fragment appear">two programs running on the same hardware need not share all of
the same (or any of the same) states</li>

</ul></li>

</ol>

</section>
<section id="slide-orgheadline17">
<h4 id="orgheadline17">The Implementation Objection</h4>

</section>
<section id="slide-orgheadline18">
<h4 id="orgheadline18">Programs vs. Implementations</h4>
<blockquote nil>
<p>

</p>

<ol>
<li>Programs are purely formal (syntactic)</li>
<li>Human minds have mental contents (semantics)</li>
<li>Syntax by itself is neither constitutive of, nor sufficient for,
semantic content</li>
<li>\(\therefore\) Programs by themselves are not constitutive of nor
sufficient for minds</li>

</ol>
</blockquote>

<ul>
<li class="fragment appear">We need to distinguish between a <i>program</i> and an <i>implementation of
the program</i></li>

</ul>

</section>
<section>

<blockquote nil>
<p>
Programs are abstract computational objects and are purely syntactic.
Certainly, no mere program is a candidate for possession of a mind.
Implementations of programs, on the other hand, are concrete systems
with causal dynamics, and are not purely syntactic. An implementation
has causal heft in the real world, and it is in virtue of this causal
heft that consciousness and intentionality arise. It is the program
that is syntactic; it is the implementation that has semantic content.
(Chalmers 1996, 327)
</p>
</blockquote>

</section>
<section id="slide-orgheadline19">
<h4 id="orgheadline19">Chalmers's Parody:</h4>
<ol>
<li class="fragment appear">Recipes are syntactic.</li>
<li class="fragment appear">Syntax is not sufficient for crumbliness.</li>
<li class="fragment appear">Cakes are crumbly.</li>
<li class="fragment appear">\(\therefore\) Implementing a recipe is insufficient for a cake.</li>

</ol>

</section>
<section>

<blockquote nil>
<p>
A recipe implicitly specifies a class of physical systems that qualify
as implementations of the recipe, and it is these systems that have
such features as crumbliness. Similarly, a program implicitly
specifies a class of physical systems that qualify as implementations
of the program, and it is these systems that give rise to such
features as minds. (Chalmers, 327)
</p>
</blockquote>
</section>
</section>
</div>
</div>
<p> Created by Colin McLear. </p>
<script src="file:///Users/Roambot/bin/reveal.js/lib/js/head.min.js"></script>
<script src="file:///Users/Roambot/bin/reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: 'c/t',
rollingLinks: true,
keyboard: true,
overview: true,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'convex', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'default',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: 'file:///Users/Roambot/bin/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'file:///Users/Roambot/bin/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'file:///Users/Roambot/bin/reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: 'file:///Users/Roambot/bin/reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }]
});
</script>
</body>
</html>
